{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pystan\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from __future__ import division\n",
    "# import ite\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "ds = tf.contrib.distributions\n",
    "use_entropy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gmm set up\n",
    "param_dim = 2\n",
    "num_mixtures =8\n",
    "radius = 0.5\n",
    "thetas = np.linspace(0, 2 * np.pi, num_mixtures + 1)[:num_mixtures]\n",
    "xs, ys = radius * np.sin(thetas), radius * np.cos(thetas)\n",
    "means_x = list([np.array([a,b]) for a,b in zip(xs,ys)])\n",
    "std = 0.05\n",
    "u_mean=tuple(zip(xs, ys))\n",
    "u_cov=tuple([(std, std)] * num_mixtures)\n",
    "def gmm(x):\n",
    "        ds = tf.contrib.distributions\n",
    "        gauss_ref = ds.Mixture(\n",
    "          cat=ds.Categorical(probs=[1.0/8]*8),\n",
    "          components=[\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[0], scale_diag=u_cov[0]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[1], scale_diag=u_cov[1]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[2], scale_diag=u_cov[2]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[3], scale_diag=u_cov[3]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[4], scale_diag=u_cov[4]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[5], scale_diag=u_cov[5]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[6], scale_diag=u_cov[6]),\n",
    "            ds.MultivariateNormalDiag(loc=u_mean[7], scale_diag=u_cov[7]),\n",
    "              \n",
    "        ])      \n",
    "        return gauss_ref.log_prob(x)\n",
    "def w1(z):\n",
    "    return tf.sin(2.*np.pi*z[0]/4.)\n",
    "def w2(z):\n",
    "    return 3.*tf.exp(-.5*(((z[0]-1.)/.6))**2)\n",
    "def w3(z):\n",
    "    return 3.*(1+tf.exp(-(z[0]-1.)/.3))**-1\n",
    "def pot1(z):\n",
    "    z = tf.transpose(z)\n",
    "    ans=.5*((tf.norm(z, ord=2, axis=0)-2.)/.4)**2 - tf.log(tf.exp(-.5*((z[0]-2.)/.6)**2) + tf.exp(-.5*((z[0]+2.)/.6)**2))\n",
    "    return -ans\n",
    "def pot2(z):\n",
    "    z = tf.transpose(z)\n",
    "    ans=.5*((z[1]-w1(z))/.4)**2\n",
    "    return -ans\n",
    "def pot3(z):\n",
    "    z = tf.transpose(z)\n",
    "    ans=-tf.log(tf.exp(-.5*((z[1]-w1(z))/.35)**2) + tf.exp(-.5*((z[1]-w1(z)+w2(z))/.35)**2))\n",
    "    return -ans\n",
    "def pot4(z):\n",
    "    z = tf.transpose(z)\n",
    "    ans=-tf.log(tf.exp(-.5*((z[1]-w1(z))/.4)**2) + tf.exp(-.5*((z[1]-w1(z)+w3(z))/.35)**2))\n",
    "    return -ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=256\n",
    "def linear(input, output_dim, scope='linear', stddev=0.01,use_SN=False, update_collection=None):\n",
    "    norm = tf.random_normal_initializer(stddev=stddev)\n",
    "    const = tf.constant_initializer(0.0)\n",
    "    with tf.variable_scope(scope):\n",
    "        w = tf.get_variable('weights', [input.get_shape()[1], output_dim], initializer=norm)\n",
    "        b = tf.get_variable('biases', [output_dim], initializer=const)\n",
    "        if use_SN:\n",
    "            print('using SN')\n",
    "            return tf.matmul(input,spectral_normed_weight(w, update_collection=update_collection))+b\n",
    "        else:\n",
    "            return tf.matmul(input, w) + b\n",
    "def posterior(eps,reuse=False):\n",
    "    with tf.variable_scope('posterior',reuse=reuse) as scope:\n",
    "        h=tf.nn.relu(linear(eps,hidden_size,'p_h1'))\n",
    "        h=tf.nn.relu(linear(h,hidden_size,'p_h2'))\n",
    "        out=linear(h,2,scope='p_out')\n",
    "        return out\n",
    "def adversary(z,reuse=False):\n",
    "    with tf.variable_scope('adversary',reuse=reuse) as scope:\n",
    "        h=tf.nn.relu(linear(z,hidden_size,'a_h1'))\n",
    "        out=linear(h,1,scope='a_out')\n",
    "        return out\n",
    "def inference(input,reuse=False):\n",
    "    with tf.variable_scope('inference',reuse=reuse) as scope:\n",
    "        h=tf.nn.relu(linear(input,hidden_size,'i_h1'))\n",
    "        h=tf.nn.relu(linear(h,hidden_size,'i_h2'))\n",
    "        out=linear(h,2,scope='i_out')\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using AC\n"
     ]
    }
   ],
   "source": [
    "batch_size=1024\n",
    "is_adapt_contrast=True\n",
    "get_logprob=gmm\n",
    "tf.reset_default_graph()\n",
    "z0=tf.random_normal([batch_size,param_dim],name='z0')\n",
    "eps=tf.random_normal([batch_size,param_dim],name='eps')\n",
    "z_=posterior(eps)\n",
    "\n",
    "beta=tf.constant(1.0)\n",
    "if is_adapt_contrast:\n",
    "    Ez_, Varz_ = tf.nn.moments(z_, [0], keep_dims=True)\n",
    "    stdz_ = tf.sqrt(Varz_) + 1e-6\n",
    "    Ez_ = tf.stop_gradient(Ez_)\n",
    "    stdz_ = tf.stop_gradient(stdz_)\n",
    "\n",
    "    zr = Ez_ + stdz_ * z0\n",
    "    znorm_ = (z_ - Ez_) / stdz_\n",
    "gauss_ref=ds.MultivariateNormalDiag(loc=[0.,0.],scale_diag=[1.0,1.0])\n",
    "\n",
    "if is_adapt_contrast:\n",
    "    print('using AC')\n",
    "    logr_=gauss_ref.log_prob(znorm_)\n",
    "    Ti=adversary(z0)\n",
    "    Td=adversary(znorm_,reuse=True)\n",
    "else:\n",
    "    logr_=gauss_ref.log_prob(z_)\n",
    "    Ti=adversary(z0)\n",
    "    Td=adversary(z_,reuse=True)\n",
    "    \n",
    "logprob=get_logprob(z_)\n",
    "mean_logprob=tf.reduce_mean(logprob)\n",
    "loss_primal=tf.reduce_mean(logr_+Td-logprob)\n",
    "\n",
    "d_loss_d=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Td,labels=tf.ones_like(Td)))\n",
    "d_loss_i=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Ti,labels=tf.zeros_like(Ti)))\n",
    "loss_dual=d_loss_i+d_loss_d\n",
    "\n",
    "entropy_term=beta*mean_logprob\n",
    "\n",
    "\n",
    "if use_entropy:\n",
    "    loss_primal+=1*entropy_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"posterior\")\n",
    "dvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"adversary\")\n",
    "# ivars=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'inference')\n",
    "popt=tf.train.AdamOptimizer(2e-4,beta1=0.5)\n",
    "dopt=tf.train.AdamOptimizer(2e-4,beta1=0.5)\n",
    "grads_primal =  popt.compute_gradients(loss_primal, var_list=pvars)\n",
    "grads_dual = dopt.compute_gradients(loss_dual, var_list=dvars)\n",
    "\n",
    "train_primal = popt.apply_gradients(grads_primal)\n",
    "train_dual = dopt.apply_gradients(grads_dual)\n",
    "\n",
    "train_step = [train_primal, train_dual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for visualization\n",
    "idx0, idx1 = 0, 1\n",
    "labels = [r'$\\mu$', r'$\\tau$', r'$\\eta_1$']\n",
    "xlabel = labels[idx0]\n",
    "ylabel = labels[idx1]\n",
    "\n",
    "plt.rc('font', size=16)\n",
    "def get_samples(sess, nbatches=10):\n",
    "    zs = np.zeros([nbatches, batch_size, param_dim])\n",
    "    for i in range(nbatches):\n",
    "        zs[i] = sess.run(z_)\n",
    "    zs = zs.reshape(-1, param_dim)\n",
    "    return zs\n",
    "def scatter(mu, tau,savepath, bbox=[-5, 5, -5, 5], xlabel=\"\", ylabel=\"\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis(bbox)\n",
    "    ax.set_aspect(1.0*4/5*abs(bbox[1]-bbox[0])/abs(bbox[3]-bbox[2]))\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "                        \n",
    "    ax.scatter(mu, tau, edgecolor='b', alpha=0.1)\n",
    "    plt.plot(xs,ys,'ro')\n",
    "#     plt.show()\n",
    "    plt.savefig(savepath)\n",
    "    \n",
    "def plot_results(save_path):\n",
    "    q = get_samples(sess, nbatches=10)\n",
    "    q1 = q[:, idx0]\n",
    "    q2 = q[:, idx1]\n",
    "    bbox = [-0.95,0.95,-0.95,0.95]\n",
    "#     bbox=[-5, 5, -5, 5]\n",
    "    scatter(q1, q2,save_path,bbox,xlabel=xlabel, ylabel=ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "def run_training(sess, niter=10000, betas=None, npretrain=0):    \n",
    "    outdir='./ce_8gmm_%.01f_%.02f'%(radius,std)\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    if betas is None:\n",
    "        betas = []\n",
    "        \n",
    "    for i in tnrange(npretrain, desc=\"Pretrain\"):\n",
    "        sess.run(train_dual)\n",
    "\n",
    "    pbar = tnrange(niter+1, desc=\"Train\")\n",
    "    for i in pbar:\n",
    "        if i >= np.size(betas):\n",
    "            beta_i = 1.\n",
    "        else:\n",
    "            beta_i = betas[i]\n",
    "                           \n",
    "        _, lp, ld= sess.run(\n",
    "                [train_primal, loss_primal, loss_dual],\n",
    "                feed_dict={beta: beta_i}\n",
    "        )\n",
    "        \n",
    "        sess.run(train_dual)\n",
    "#         sess.run(train_dual)\n",
    "        if i%10000==0:\n",
    "            \n",
    "            samples=get_samples(sess,nbatches=20)\n",
    "            if use_entropy:\n",
    "                plot_results(os.path.join(outdir,'EN_%08d.png'%i))\n",
    "                np.save(os.path.join(outdir,'EN_%08d'%i),samples)\n",
    "            else:\n",
    "                plot_results(os.path.join(outdir,'%08d.png'%i))\n",
    "                np.save(os.path.join(outdir,'%08d'%i),samples)\n",
    "        pbar.set_description(\"lp=%.3f, ld=%.3f\"  % (lp, ld))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08c17ca74d945e98e57c30e7aa4c236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', description=u'Pretrain: ', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ea61283a1449a08c3be28a91a722e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Train: ', max=300001), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_max = 300000\n",
    "# AVB\n",
    "# run_training(sess, niter=iter_max,npretrain=0)\n",
    "run_training(sess, niter=iter_max,betas=np.linspace(0.9,0.0,iter_max-10000),npretrain=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
